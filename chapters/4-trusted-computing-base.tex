\chapter{Correctness Theorem and Verilog Semantics}%
\label{sec:trusted-computing-base}

\begin{chapsummary}
  This chapter describes the trusted computing base of Vericert, which includes
  the final correctness theorem and the formalised Verilog semantics.
\end{chapsummary}

\noindent The trusted computing base of verified software such as CompCert is
the code that is not verified, and therefore needs to be trusted by the user
when using the tool or the correctness theorem.  This is in contrast to the
untrusted code that has been verified, and therefore cannot introduce bugs.  It
is important to understand the trusted computing base of verified software such
as CompCert and Vericert to recognise where bugs could still be introduced.
When \textcite{yang11_findin_under_bugs_c_compil} fuzz tested CompCert and all
bugs that were found were in the unverified, trusted parts of the compiler.  For
example, there were bugs in the unverified front end of CompCert, which was then
addressed by reducing the trusted computing base by verifying the correctness of
the C parser~\cite{jourdan12_valid_lr_parser}.  Another bug was found because of
a missing constraint in the semantics of the PowerPC.

The trusted computing base of CompCert comprises the Coq theorem prover itself,
the OCaml extraction from Coq which is unverified, the front end semantics of C
which may not model the C standard faithfully, and finally the semantics for
each assembly language~\cite{monniaux22_tcbcvc}.  In general, the trusted
computing base of Vericert is the same as that of CompCert, the main two
differences are described in this section, and they are the correctness theorem
and the target Verilog semantics.

\section{Formulating the Correctness Theorem}

The main correctness theorem is analogous to that stated in \compcert{} and
described in \cref{sec:bg:correctness-theorem}: for all \gls{Clight} source programs
$C$, if the translation to the target Verilog code succeeds, $\mathit{safe}(C)$
holds and the target Verilog has behaviour $\mathcal{B}$ when simulated, then
$C$ will have the same behaviour $\mathcal{B}$.  The predicate
$\mathit{safe}(C)$ means all observable behaviours of $C$ are safe, which can be
defined as
$\forall \mathcal{B},\ C \Downarrow \mathcal{B} \implies \mathcal{B} \not\in
\texttt{Wrong}$.  A behaviour is in \texttt{Wrong} if it can \enquote{go wrong},
meaning it contains undefined behaviour.  In \compcert{}, a behaviour is also
associated with a trace of I/O events, but since external function calls are not
supported in \vericert{}, this trace will always be empty.

\begin{theorem}
  Whenever the translation from $C$ succeeds and produces Verilog $V\!$, and all
  observable behaviours of $C$ are safe, then $V\!$ has behaviour $\mathcal{B}$
  only if $C$ has behaviour $\mathcal{B}$.

  {\normalfont\begin{equation} \forall C\ V\ \mathcal{B}\ldotp\quad \yhfunction{HLS} (C)
      = \ccok{V} \land \mathit{safe}(C) \implies (V \Downarrow \mathcal{B}
      \implies C \Downarrow \mathcal{B}).
  \end{equation}}
\end{theorem}

Why is this correctness theorem also the right one for HLS?  It could be argued
that hardware inherently runs forever and therefore does not produce a
definitive final result.  This would mean that the \compcert{} correctness
theorem would probably be unhelpful with proving hardware correctness, as the
behaviour would always be divergent.  However, in practice, HLS does not
normally produce the top-level of the design that connects all the components of
the design together, therefore needing to run forever.  Rather, \gls{HLS} often
produces smaller components that take an input, execute, and then terminate with
an answer.  To start the execution of the hardware and to signal to the HLS
component that the inputs are ready, the $\resetreg$ signal is set and unset.
Then, once the result is ready, the $\finishreg$ signal is set and the result
value is placed in $\returnreg$.  This is encoded in the Verilog semantics.  The
correctness theorem therefore also uses these signals, and the proof shows that
once the $\finishreg$ flag is set, the value in $\returnreg$ is correct
according to the semantics of Verilog and CompCert C.  Note that the compiler is
allowed to fail and not produce any output; the correctness theorem only applies
when the translation succeeds.

How can we prove this theorem?  Note that like in CompCert, this theorem can be
proven using a backward simulation.  The same proof technique can be used to
verify the correctness of \vericert{}, extending the forward simulation from
\rtl{} to Verilog.  Then, by proving that the Verilog semantics are
\emph{deterministic}, the composition of forward simulation in CompCert, as well
as the simulations in Vericert imply the backward simulation needed to prove the
theorem.  For each transformation this dissertation will therefore describe how
the forward simulations are proven.

All the corollaries proven using the top-level CompCert correctness theorem
still hold, and do not have to be proven again or modified, because the
correctness theorem is unchanged except for the target language semantics.  Note
however that Vericert does not support separate compilation of translation
units, and needs a main function.  Any corollaries and top-level theorems about
the linking of translation units therefore are not needed and hold vacuously, as
compilation would fail on these translation units.

\section{A Formal Semantics for Verilog}\label{sec:verilog}

This section describes the Verilog semantics that was chosen for the target
language, including the changes that were made to the semantics to make it a
suitable HLS target.  The Verilog standard is quite
large~\cite{06_ieee_stand_veril_hardw_descr_languag,
  05_ieee_stand_veril_regis_trans_level_synth}, and is split into two standards,
one for synthesis and one for simulation.  The simulation semantics are similar
to semantics one would expect, assigning detailed behaviour to each part of the
Verilog language.  However, in contrast to programming languages,
\textquote[{\textcite[p.~699]{weste10_cvd}}]{HDLs are better understood as a
  shorthand for describing digital hardware}, as synthesis tools try to
understand what kind of hardware the user wanted to describe, which may
sometimes behave differently to simulating the original Verilog design.  It is
therefore important to take that into account in the Verilog semantics and
ensure that after synthesis the design still behaves according to the semantics.
Luckily, the syntax and semantics can be reduced to a small subset that
\vericert{} can target.  This section also describes how \vericert{}'s
representation of memory differs from \compcert{}'s memory model.

The Verilog semantics I use is ported to Coq from a semantics written in HOL4 by
\textcite{lööw19_proof_trans_veril_devel_hol} which was used to prove the
translation from a HOL4 description of the hardware to
Verilog~\cite{lööw19_verif_compil_verif_proces}.  This semantics is quite
practical as it is restricted to a small subset of Verilog, which can
nonetheless be used to model the hardware constructs required for HLS.  The main
features that are excluded are continuous assignment and combinational
always-blocks; these are modelled in other semantics such as that
by~\textcite{meredith10_veril}.

The semantics of Verilog is inherently parallel as it needs to describe hardware.  The main construct in Verilog is the
always-block.  A module can contain multiple always-blocks, all of which run in
parallel.  These always-blocks further contain statements such as if-statements
or assignments to variables.  Only \emph{synchronous} logic is supported, which
means that the always-block is triggered on (and only on) the positive or
negative edge of a clock signal.  However, combinational expressions can still
be expressed within synchronous assignments, so in practice these features are
not needed if the Verilog is being generated.

The semantics combines the big-step and small-step styles. The overall execution
of the hardware is described using a small-step semantics, with one small step
per clock cycle; this is appropriate because hardware is routinely designed to
run for an unlimited number of clock cycles and the big-step style is ill-suited
to describing infinite executions. Then, within each clock cycle, a big-step
semantics is used to execute all the statements.  An example of a rule for
executing an always-block that is triggered at the positive edge of the clock is
shown below, where $\Sigma$ is the state of the registers in the module and $s$
is the statement inside the always-block:
%
\begin{equation}
  \inferrule[Always]{(\Sigma, s)\downarrow_{\text{stmnt}} \Sigma'}{(\Sigma,
    \yhkeyword{always} \texttt{ @(}\yhkeyword{posedge}\texttt{ clk) } s) \downarrow_{\text{always}^{+}} \Sigma'}
\end{equation}
%
This rule says that assuming the statement $s$ in the always-block runs with
state $\Sigma$ and produces the new state $\Sigma'$, the always-block will
result in the same final state.  The rule is triggered once for every clock
cycle, on the positive edge of the clock (denoted by the $\cdot^{+}$).

Two types of assignments are supported in always-blocks: nonblocking and
blocking assignment.  Nonblocking assignments all take effect simultaneously at
the end of the clock cycle, while blocking assignments happen instantly so that
later assignments in the clock cycle can pick them up.  This means that
sequential logic is usually expressed using nonblocking assignments, which will
often write the assignment to a register that can be read in the next cycle,
whereas blocking assignment is used for combinational expressions within the
cycle and could therefore be thought of as a wire instead.  When writing
Verilog, this is only a guideline, and in practice the tools may create
registers for blocking assignments if the synthesis tool sees that they are used
to store state.  To mitigate this, the formal semantics specify that
communication between always blocks can only happen through nonblocking
assigment, and blocking assignment can only be used for local variables, so that
these likely will result in wires in the final hardware.  These two restrictions
do not only help produce more predictable hardware that behaves like the
simulation, but it also simplifies the overall semantics of Verilog.  As
only clocked always-blocks are supported, communication between these
always-blocks can only be performed through nonblocking assignment, which means
that the order in which the always blocks are executed does not matter and will
always result in the same final state.

To model both of these assignments, the state $\Sigma$ has to be split into two
association maps: $\Gamma$, which contains the current values of all variables
and arrays, and $\Delta$, which contains the values that will be assigned at the
end of the clock cycle. $\Sigma$ can therefore be defined as follows:
$\Sigma = (\Gamma, \Delta)$.  Blocking and Nonblocking assignment can therefore
be expressed as follows:
%
\begin{equation}
  \inferrule[Blocking Reg]{\yhkeyword{name}\ d = \ccok{n} \\ (\Gamma, e)
    \downarrow_{\text{expr}} v}{((\Gamma, \Delta), d \mathrel{\yhkeyword{=}} e\yhkeyword{;}) \downarrow_{\text{stmnt}} (\Gamma[n \mapsto v], \Delta)}\qquad\inferrule[Nonblocking Reg]{\yhkeyword{name}\ d = \ccok{n} \\ (\Gamma, e) \downarrow_{\text{expr}} v}{((\Gamma, \Delta), d \mathrel{\yhkeyword{<=}} e\yhkeyword{;}) \downarrow_{\text{stmnt}} (\Gamma, \Delta [n \mapsto v])}
\end{equation}
%
where assuming that $\downarrow_{\text{expr}}$ evaluates an expression $e$ to a
value $v$, the nonblocking assignment $d\ \yhkeyword{ <= } e$ updates the future
state of the variable $d$ with value $v$.

Finally, the following rules dictate how the whole module runs in one clock
cycle:
%
\phantomsection{}
\begin{equation}
  \inferrule[Module$^+_1$]{(\Gamma, \Delta, a) \downarrow_{\text{always}^{+}}
    (\Gamma', \Delta') \\ (\Gamma', \Delta', \vec{m})
    \downarrow_{\mathrm{module}^{+}} (\Gamma'', \Delta'')}{(\Gamma, \Delta, a \mathbin{::} \vec{m})\ \downarrow_{\mathrm{module}^{+}}
    (\Gamma'', \Delta'')}\label{infer:module_plus}\quad
  \inferrule[Module$^+_2$]{ }{(\Gamma, \Delta, \varnothing)\ \downarrow_{\mathrm{module}^{+}}
    (\Gamma, \Delta)}
\end{equation}
\phantomsection{}
\begin{equation}
  \inferrule[Program]{(\Gamma, \epsilon, \vec{m})\ \downarrow_{\mathrm{module}^{+}}
    (\Gamma', \Delta')}{(\Gamma, \yhkeyword{module } \yhconstant{main}
    \yhkeyword{(...);}\ \vec{m}\ \yhkeyword{endmodule})
    \downarrow_{\text{program}} (\Gamma' \verilogmerge \Delta')}\label{infer:module_old}
\end{equation}
%
where $\Gamma$ is the initial state of all the variables, $\epsilon$ is the
empty map because the $\Delta$ map is assumed to be empty at the start of the
clock cycle, and $\vec{m}$ is a list of variable declarations and always-blocks
that $\downarrow_{\mathrm{module}^{+}}$ evaluates sequentially to obtain
$(\Gamma', \Delta')$.  The final state is obtained by merging these maps using
the $\verilogmerge$ operator, which gives priority to the right-hand operand in
a conflict. This rule ensures that the nonblocking assignments overwrite at the
end of the clock cycle any blocking assignments made during the cycle.

\subsection{Changes to the semantics}

Five changes were made to the semantics proposed by
\textcite{lööw19_proof_trans_veril_devel_hol} to make it suitable as an HLS
target.

\paragraph{Adding array support}
The main change is the addition of support for arrays, which are needed to model
\gls{BRAM} in Verilog.  \gls{BRAM} is needed to model the stack in C
efficiently, without having to declare a variable for each possible stack
location.  In the original semantics, RAMs (as well as inputs and outputs to the
module) could be modelled using a function from variable names to values, which
could be modified accordingly to model inputs to the module.  However, this
representation does not support merging of individual array elements.  This is
quite an abstract description of memory and can also be expressed as an array
instead, which is the path I took.  This requires the addition of array
operators to the semantics and correct reasoning of loads and stores to the
array in different always-blocks simultaneously.  Consider the following Verilog
code:
%
  \begin{center}
\begin{minted}[xleftmargin=40pt,linenos]{systemverilog}
logic [31:0] x[1:0];
always @(posedge clk) begin
  x[0] = 1;
  x[1] <= 1;
end
\end{minted}
  \end{center}
%
This always-block modifies one array element using blocking assignment and then
a second using nonblocking assignment.  If the existing semantics were used to
update the array, then during the merge, the entire array \texttt{x} from the
nonblocking association map would replace the entire array from the blocking
association map.  This would replace \texttt{x[0]} with its original value and
therefore behave incorrectly. Accordingly, I modified the maps so they record
updates on a per\?element basis. Our state $\Gamma$ is therefore further split
up into $\Gamma_{r}$ for instantaneous updates to variables, and $\Gamma_{a}$
for instantaneous updates to arrays ($\Gamma = (\Gamma_{r}, \Gamma_{a})$);
$\Delta$ is split similarly ($\Delta = (\Delta_{r}, \Delta_{a})$). The merge
function then ensures that only the modified indices get updated when
$\Gamma_{a}$ is merged with the nonblocking map equivalent $\Delta_{a}$.

The implementation of arrays is done using dependently typed arrays that keep
track of their size, such that out-of-bounds accesses can be detected and
handled appropriately.  \Cref{sec:verilog:memory} describes the implementation
of this memory model in more detail, comparing it to the CompCert memory model.

\paragraph{Adding negative edge support}

To reason about circuits that execute on the negative edge of the clock (such as
our \gls{BRAM} interface described briefly in \cref{sec:itv:rtlpar-to-htl}),
support for negative-edge-triggered always-blocks was added to the semantics.
This is shown in the modifications of the \nameref{infer:module} rule shown
below:
%
\phantomsection{}
\begin{equation}
  \inferrule[Program$^\pm$]{(\Gamma, \epsilon, \vec{m})\ \downarrow_{\text{module}^{+}} (\Gamma', \Delta') \\ (\Gamma' \verilogmerge \Delta', \epsilon, \vec{m}) \downarrow_{\text{module}^{-}} (\Gamma'', \Delta'')}{(\Gamma, \yhkeyword{module}\ \yhconstant{main} \yhkeyword{(...);}\ \vec{m}\ \yhkeyword{endmodule}) \downarrow_{\mathrm{program}^\pm} (\Gamma''\verilogmerge \Delta'')}\label{infer:module}
\end{equation}
%
The main execution of the module $\downarrow_{\text{module}}$ is split into
$\downarrow_{\text{module}^{+}}$ and $\downarrow_{\text{module}^{-}}$, which are
rules that only execute always-blocks triggered at the positive and at the
negative edge respectively. The positive-edge-triggered always-blocks are
processed in the same way as in the original \nameref{infer:module_old}
rule. The output maps $\Gamma'$ and $\Delta'$ are then merged and passed as the
blocking assignments map into the negative edge execution, so that all the
blocking and nonblocking assignments are resolved.  Finally, all the
negative-edge-triggered always-blocks are processed and merged to give the final
state.

\paragraph{Adding declarations} Explicit support for declaring inputs, outputs
and internal variables was added to the semantics to make sure that the
generated Verilog also contains the correct declarations.  This adds some
guarantees to the generated Verilog and ensures that it synthesises and
simulates correctly.  Otherwise, if there are bugs in the insertion of
declarations, the Verilog would fail to synthesise or simulate.  This is done by
adding a declaration entry for each register that is used.

\paragraph{Removing support for external inputs to modules} Support for
receiving external inputs was removed from the semantics.  The main module in
Verilog models the main function in C, and since the inputs to a C function
should not change during its execution, there is no need for external inputs for
Verilog modules.  In addition to that, this external inputs function was also
used to model memory in the original semantics, which is not needed as arrays
are fully supported.  This means that the \gls{BRAM} can be faithfully modelled
as Verilog and it can be reasoned about.

\paragraph{Simplifying representation of bitvectors} Finally, I use 32-bit
integers to represent bitvectors rather than arrays of booleans. This is because
\vericert{} (currently) only supports types represented by 32 bits.  However,
extending Vericert would likely not require the full flexibility of bitvectors
as arrays of booleans either, as long as fine-grained bit-size optimisations for
registers are not introduced, because the Verilog subset could be restriced to
bitvectors of sizes 4, 8, 16, 32 and 64, which are already supported by the
CompCert integer type.

\subsection{Integrating the Verilog semantics into CompCert's model}
\label{sec:verilog:integrating}

\begin{figure*}
  \centering
  \begin{minipage}{1.0\linewidth}
    \begin{mathpar}
      \inferrule[Step]{\Gamma_r[\resetreg] = 0 \\ \Gamma_r[\finishreg] = 0 \\ (m, (\Gamma_r, \Gamma_a))\ \downarrow_{\mathrm{program}^\pm} (\Gamma_r', \Gamma_a')}{\yhconstant{State}\ \mathit{sf}\ m\ \ \Gamma_r[\statereg]\ \ \Gamma_r\ \Gamma_a \longrightarrow \yhconstant{State}\ \mathit{sf}\ m\ \ \Gamma_r'[\statereg]\ \ \Gamma_r'\ \Gamma_a'}\label{infer:stepstate}\and
      %
      \inferrule[Finish]{\Gamma_r[\finishreg] = 1}{\yhconstant{State}\ \mathit{sf}\ m\ n\ \Gamma_r\ \Gamma_a \longrightarrow \yhconstant{Returnstate}\ \mathit{sf}\ \Gamma_r[ \returnreg]}\label{infer:finishstate}\and
      %
      \inferrule[Call]{ }{\yhconstant{Callstate}\ \mathit{sf}\ m\ \vec{r} \longrightarrow \yhconstant{State}\ \mathit{sf}\ m\ n\ ((\yhfunction{init\_params}\ \vec{r}\ a)[\statereg \mapsto n, \finishreg \mapsto 0, \resetreg \mapsto 0])\ \epsilon}\label{infer:callstate}\and
      %
      \inferrule[Return]{ }{\yhconstant{Returnstate}\ (\yhconstant{Stackframe}\ r\ m\ \mathit{pc}\ \Gamma_r\ \Gamma_a :: \mathit{sf})\ v \longrightarrow \yhconstant{State}\ \mathit{sf}\ m\ \mathit{pc}\ (\Gamma_{r} [ \statereg \mapsto \mathit{pc}, r \mapsto v ])\ \Gamma_{a}}\label{infer:returnstate}
    \end{mathpar}
  \end{minipage}
  \caption{Top-level small-step semantics for Verilog modules in \compcert{}'s computational framework.}%
  \label{fig:inference_module}
\end{figure*}

The \compcert{} computation model defines a set of states through which
execution passes. In this subsection, I explain how I extend our Verilog
semantics with four special-purpose registers in order to integrate it into
\compcert{}.

\compcert{} executions pass through three main states, which have been adapted
to the Verilog semantics by using association maps for the registers and arrays.
These three states otherwise match the states used by other languages,
simplifying the integration of the Verilog semantics into \compcert{}.  These
states, together with the transitions defined on the states, act as a weak
calling convention for the hardware produced by the \gls{HLS} tool.  These are
therefore not part of the general Verilog semantics themselves, but part of the
Verilog semantics for designs produced through \gls{HLS}.
\begin{description}
\item[\texttt{State} $\mathit{sf}$ $m$ $v$ $\Gamma_{r}$ $\Gamma_{a}$] The main
  state when executing a function, with stack frames $\mathit{sf}$, the top-level module $m$, current state $v$ and variable states $\Gamma_{r}$ and
  $\Gamma_{a}$.  The regular execution of the module will proceed from
  \texttt{State} to \texttt{State} until the \textit{fin} signal is high.
  \item[\texttt{Callstate} $\mathit{sf}$ $m$ $\vec{r}$] The state that is
    reached when a function is called, with the stack frames
    $\mathit{sf}$, the top-level module $m$ and arguments $\vec{r}$.  In practice, as
    there are no function calls in the Verilog semantics, this state is only
    reached at the start of the execution.  A better name for this state
    might therefore be \texttt{Resetstate}, as it corresponds to the behaviour
    of the module when the reset input was asserted.
  \item[\texttt{Returnstate} $\mathit{sf}$ $v$] The state that is reached when a
    function returns back to the caller, with stack frames $\mathit{sf}$ and
    return value $v$.
\end{description}

To support this computational model, I extend the Verilog module I generate with
the following four registers and a \gls{BRAM} block:

\begin{description}
\item[program counter] The program counter is modelled using a register that
  keeps track of the state, named $\statereg$.  This register should always
  contain the current state, and will be checked on the next transition to pick
  the next state.
\item[function entry point] When a function is called, the entry point denotes
  the first instruction that will be executed. This can be modelled using a
  reset signal that sets the state accordingly, denoted as $\resetreg$.  In
  this translation, function calls are not implemented, so the reset signal
  resets the main module and sets the state parameter for this main module.
\item[return value] The return value can be modelled by setting a finished flag
  to 1 when the result is ready, and putting the result into a 32-bit output
  register. These are denoted as $\finishreg$ and $\returnreg$ respectively.
  Instead of a return instruction, checking that $\finishreg$ is 1 should
  signal that the result is stored in the return register.
\item[stack] The function's stack frame can be modelled as a \gls{BRAM} block, which is
  implemented using an array in the module, and denoted as $\stackreg$.
  When the main function is initially called, it allocates a stack frame, which
  should match the \gls{BRAM} block that was implemented.
\end{description}

\Cref{fig:inference_module} shows the inference rules for moving between the
computational states.  The first, \nameref{infer:stepstate}, is the normal rule
of execution.  It defines one step in the \texttt{State} state, assuming that
the module is not being reset, that the finish state has not been reached yet,
that the current and next state are $v$ and $v'$, and that the module runs from
state $\Gamma$ to $\Gamma'$ using the \nameref{infer:stepstate} rule.  This rule
also ensures that the state register contains the value of the current state, by
checking the value of $\Gamma_r[\statereg]$.  It is then ensured that the resulting
state is also the value of the $\statereg$ register in the updated association map
$\Gamma'_r[\statereg]$.

The \nameref{infer:finishstate} rule returns the final value of running the
module and is applied when the $\finishreg$ register is set; the return value
is then taken from the $\returnreg$ register.

Note that there is no step from \texttt{State} to \texttt{Callstate}; this is
because function calls are not supported, and it is therefore impossible in our
semantics ever to reach a \texttt{Callstate} except for the initial call to
main. So the \nameref{infer:callstate} rule is only used at the very beginning
of execution; likewise, the \nameref{infer:finishstate} rule is only matched for
the final return value from the main function.  As a result, the final rule
called \nameref{infer:returnstate} is never reached in practice, as the stack will always be empty.  This rule could ideally therefore be removed,
however it is still present to match the state transitions used in CompCert.  To
remove this rule, one would have to show that the stack remains empty by
induction over the semantics.

In addition to these rules, a valid semantics also needs an intial state and a
final state.  These are therefore defined as follows:
%
\begin{mathpar}
  \inferrule[Initial]{\yhfunction{is\_internal}\
    P.\texttt{main}}{\yhfunction{initial\_state}\ (\yhconstant{Callstate}\ []\
    P.\texttt{main}\ [])}%
  \label{infer:initialstate}
  \and
  \inferrule[Final]{ }{\yhfunction{final\_state}\ (\yhconstant{Returnstate}\ []\
    n)\ n}%
  \label{infer:finalstate}
\end{mathpar}

\noindent where the initial state is the \texttt{Callstate} with an empty stack and no arguments for the \texttt{main} function of program $P$, where this
\texttt{main} function needs to be in the current translation unit.  The final
state results in the program output of value $n$ when reaching a
\texttt{Returnstate} with an empty stack.

\subsection{Memory model}\label{sec:verilog:memory}

The Verilog semantics do not define a memory model for Verilog, as this is not
needed for a hardware description language.  There is no preexisting
architecture that Verilog will produce; it can describe any memory layout that
is needed.  Instead of having a specific semantics for memory, the Verilog
semantics only needs to support the language features that can produce these
different memory layouts, these being Verilog arrays.  I therefore define
semantics for updating Verilog arrays using blocking and nonblocking assignment.
This makes it possible to describe many different memory layouts in Verilog,
providing a lot of flexibility.  I then have to develop a memory layout that
will be targeted by the \gls{HLS} tool and prove that the C memory model that
\compcert{} uses matches the interpretation of arrays used in Verilog together
with the memory layout that was chosen.  The \compcert{} memory model is
infinite, whereas our representation of arrays in Verilog is inherently finite.
There have already been efforts to define a general finite memory model for all
intermediate languages in \compcert{}, such as CompCertS~\cite{besson18_compc}
or CompCert-TSO~\cite{sevcik13_compc}, or keeping the intermediate languages
intact and translating to a more concrete finite memory model in the back end,
such as in Comp\-Cert\-ELF~\cite{wang20_compc}.  I also define such a
translation from \compcert{}'s standard infinite memory model to finite arrays
that can be represented in Verilog.  There is therefore no more notion of an
abstract memory model and all the interactions to memory are encoded in the
hardware itself.

\definecolor{compcertmemmodel}{HTML}{e2ccea}
\definecolor{vericertmemmodel}{HTML}{cbe1db}
\definecolor{compcertmemmodeldark}{HTML}{5b2c6d}
\definecolor{vericertmemmodeldark}{HTML}{386156}
\begin{figure}
  \centering
  \begin{tikzpicture}[>=Latex,font=\sffamily]
    \fill[compcertmemmodel,rounded corners=3pt] (0,1) rectangle (5,-5);
    \fill[vericertmemmodel,rounded corners=3pt] (7,1) rectangle (12.5,-5);
    \node[right] at (0,0.7) {\footnotesize \textbf{\compcert{}'s Memory Model}};
    \node[right] at (7,0.7) {\footnotesize \textbf{Verilog Memory
        Representation}};
    \node[right] (baselabel) at (0.2,-1.3) {\small \textbf{\texttt{base}}};
    \node[right] (x0) at (0.2,-1.9) {\small \texttt{0}};
    \node[right] (x1) at (0.2,-2.5) {\small \texttt{1}};
    \node[rotate=90] (x2) at (0.43,-3.1) {$\cdots$};
    \foreach \x in {0,...,6}{%
      \node[right] (s\x) at (2.5,-1-\x*0.3) {\small \texttt{\x}};
      \node[right] (t\x) at (4,-1-\x*0.3) {};
      \draw[->] (s\x) -- (t\x);
    }
    \path (s0) ++(-0.3,0.6) node[right] {\small\textbf{\texttt{addr}}};
    \path (t0) ++(0.65,0.6) node[left] {\small\textbf{\texttt{data}}};
    \node[right] at (t0) {\small \texttt{DE}};
    \node[right] at (t1) {\small \texttt{AD}};
    \node[right] at (t2) {\small \texttt{BE}};
    \node[right] at (t3) {\small \texttt{EF}};
    \node[right] at (t4) {\small \texttt{12}};
    \node[right] at (t5) {\small \texttt{34}};
    \node[right] at (t6) {\small \texttt{56}};
    \node[right] at (3.1,-3.1) {$\cdots$};

    \node[right] at (3.1,-4) {$\cdots$};
    \draw[line width=1.7mm,->] (5,-2.5) -- (6.9,-2.5);

    \draw[->] (x0) -- (s3);
    \draw[->] (x1) -- (2.5,-4);
    \node at (2.5,-4.7) {\small \texttt{x[0] = 0xDEADBEEF;}};

    \begin{scope}[xshift=2.5mm,yshift=3mm]
      \draw (7.2,-1.2) rectangle (9.4,-3.9); \draw (9.6,-1.2) rectangle
      (11.8,-3.9);

      \foreach \x in {0,...,8}{%
        \draw (7.2,-1.2-\x*0.3) -- (9.4,-1.2-\x*0.3); \draw (9.6,-1.2-\x*0.3) --
        (11.8,-1.2-\x*0.3); \node (b\x) at (8.3,-1.35-\x*0.3) {}; \node (nb\x)
        at (10.7,-1.35-\x*0.3) {}; }

      \node[scale=1.2] at (b0) {\tiny\texttt{0: Some 00000000}};
      \node[scale=1.2] at (b1) {\tiny\texttt{1: Some 12345600}};
      \node[scale=1.2] at (b2) {\tiny\texttt{2: Some 00000000}};
      \node[scale=1.2] at (b3) {\tiny\texttt{3: Some 00000000}};
      \node[scale=1.2] at (b4) {\tiny\texttt{4: Some 00000000}};
      \node[scale=1.2] at (b5) {\tiny\texttt{5: Some 00000000}};
      \node[scale=1.2] at (b6) {\tiny\texttt{6: Some 00000000}};
      \node[scale=1.2] at ($(b7) - (0,0.05)$) {$\cdots$}; \node[scale=1.2] at
      (b8) {\tiny\texttt{N: Some 00000000}};

      \node[scale=1.2] at (nb0) {\tiny\texttt{0: Some DEADBEEF}};
      \node[left,scale=1.2] at (nb1) {\tiny\texttt{1: None}};
      \node[left,scale=1.2] at (nb2) {\tiny\texttt{2: None}};
      \node[left,scale=1.2] at (nb3) {\tiny\texttt{3: None}};
      \node[left,scale=1.2] at (nb4) {\tiny\texttt{4: None}};
      \node[left,scale=1.2] at (nb5) {\tiny\texttt{5: None}};
      \node[left,scale=1.2] at (nb6) {\tiny\texttt{6: None}}; \node[scale=1.2]
      at ($(nb7) - (0,0.05)$) {$\cdots$}; \node[left,scale=1.2] at (nb8)
      {\tiny\texttt{N: None}};

      \node at (8.3,-0.9) {$\Gamma_{a}$}; \node at (10.7,-0.9) {$\Delta_{a}$};
    \end{scope}

    \node at (9.5,-4.7) {\small \texttt{stack[0] <= 0xDEADBEEF;}};

    \draw[very thick,draw=vericertmemmodeldark] (7,-4.3) -- (12.5,-4.3);
    \draw[very thick,draw=compcertmemmodeldark] (0,-4.3) -- (5,-4.3);
    \draw[very thick,draw=vericertmemmodeldark] (7,0.3) -- (12.5,0.3);
    \draw[very thick,draw=compcertmemmodeldark] (0,0.3) -- (5,0.3);
  \end{tikzpicture}
  \caption[Change in the memory model during the translation of \textsc{Rtl}
  into \textsc{Htl}.]{Change in the memory model during the translation of
    \rtl{} into \htl{}.  The state of the memories in each case is recorded
    straight after the execution of the store to
    memory.}\label{fig:memory_model_transl}
\end{figure}

This translation is represented in \cref{fig:memory_model_transl}.
\compcert{}'s memory model is represented as a map from blocks to maps from
memory addresses to memory contents.  Each block represents an area in memory;
for example, a block can represent a global variable or a stack for a function.
CompCert also includes permissions that are associated with each block, which
are lost in the translation to arrays.  In contrast, the array has a static
size, which has to be the same size as the writable addresses in \compcert{}'s
memory.

Because there are no global variables in the C code, only the stack of the main
function will be allocated in the memory.  Our Verilog semantics defines two
finite arrays of optional values, one for the blocking assignments map
$\Gamma_{\mathrm{a}}$ and one for the nonblocking assignments map
$\Delta_{\mathrm{a}}$.  The optional values are present to ensure correct
merging of the two association maps at the end of the clock cycle, so that
information about which cells of the array were modified is present.  The
invariant used in the proofs is that block associated with the function stack
should be equivalent to the merged representation of the $\Gamma_{\mathrm{a}}$
and $\Delta_{\mathrm{a}}$ maps.

In particular, note that the Verilog arrays are word-addressable instead of the
CompCert memory model which is byte-addressable.  The instruction set
architectures of \glspl{CPU} typically specify memory as being byte-addressable,
however, the implementation of the memory is not that straightforward.
\Glspl{CPU} usually implement multiple levels of caching as well as the
conversion from virtual addresses to physical addresses and may operate on byte-
or word-addressable memories behind the byte-addressable interface.  Often, the
performance of the caches will be tuned to provide the best performance for
reading and writing words to memory.  This makes it possible to have good
general performance, and makes it possible to interact with larger, but slower
memories such as \gls{DRAM}.  However, Vericert assumes that it is targeting an
\gls{FPGA} without external \gls{DRAM}, so only fast \gls{BRAM} memory is used.
This means that the memory architecture can be specialised to work well with
words without using a complex memory architecture, by directly using a
word-addressable \gls{BRAM}.  A single \gls{BRAM} is enough to support this
subset of C that is translated to Verilog.

% However, in practice, assigning and reading from an array directly in the
% state machine will not produce a memory in the final hardware design, as the
% synthesis tool cannot identify the array as having the necessary properties
% that a \gls{BRAM} needs, even though this is the most natural formulation of
% memory.  Even though theoretically the memory will only be read from once per
% clock cycle, the synthesis tool cannot ensure that this is true, and will
% instead create a register for each memory location.  This increases the size
% of the circuit dramatically, as the \gls{BRAM} on the FPGA chip will not be
% reused.  Instead, the synthesis tool expects a specific interface that ensures
% these properties, and will then transform the interface into a proper
% \gls{BRAM} during synthesis.  Therefore, a translation has to be performed
% from the naive use of memory in the state machine, to a proper use of a memory
% interface.

\subsection{Deterministic Verilog semantics}%
\label{sec:proof:deterministic}

Finally, to integrate the Verilog semantics into CompCert's backward simulation
framework, we need to show that the Verilog semantics is deterministic. This
result allows us to replace the forward simulations I have proved with the
desired backward simulations.  This was proven for the small-step semantics
shown in \cref{fig:inference_module}.

\begin{lemma}\label{lemma:deterministic}
  If a Verilog program $V\!$ admits behaviours $B_1$ and $B_2$, then $B_1$ and
  $B_2$ must be the same.

  {\normalfont\begin{equation}
    \forall V\ B_{1}\ B_{2}\ldotp\quad V \Downarrow B_{1} \land V \Downarrow B_{2} \implies B_{1} = B_{2}.
  \end{equation}}
\end{lemma}

\begin{proof}[Proof sketch]
  The Verilog semantics is deterministic because the order of operation of all
  the constructs is defined, so there is only one way to evaluate the module,
  and hence only one possible behaviour.  In particular, non-determinism in the
  simulation of Verilog designs often comes from the fact that always-blocks are
  evaluated in an arbitrary order.  However, as I ensure that always-blocks only
  communicate using nonblocking assignment, the order of evaluation does not
  change the final state, meaning a sequential evaluation of always-blocks can
  be chosen.
\end{proof}

\section{Summary}

In conclusion, the trusted computing base of Vericert is similar to that of
CompCert.  The correctness theorem can remain unchanged, except for the change
of the target language semantics.  The Verilog semantics can be formalised
within CompCert's semantic framework.  I reuse an existing semantics by
\textcite{lööw19_proof_trans_veril_devel_hol} and modify it to be a suitable
\gls{HLS} target, in addition to integrating the semantics into CompCert's
general state transition framework for its intermediate languages.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% TeX-engine: luatex
%%% End:
