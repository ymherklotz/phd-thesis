\chapter{Introduction}%
\label{sec:introduction}

%% Motivation for why HLS might be needed

% \JW{A few high-level comments: \begin{enumerate} \item Create more tension
%   from the start by making the reader doubt whether existing HLS tools are
%   trustworthy. \item The intro currently draws quite a bit of motivation from
%   Lidbury et al. 2015, but we should also now lean on our FPGA submission
%   too. \item I wonder whether the paragraph `To mitigate the problems...'
%   should be demoted to a `related work' discussion (perhaps as a subsection
%   towards the end of the introduction). It outlines (and nicely dismisses)
%   some existing attempts to tackle the problem, which is certainly useful
%   motivation for your work, especially for readers already familiar with HLS,
%   but I feel that it's not really on the critical path for understanding the
%   paper.\end{enumerate}}

% \NR{I couldn't have subsections in comments so I have appended my writing to
% the bottom of this file.}\YH{The original intro is in the archive, we can
% maybe merge them in the future a bit.}

As latency, throughput, and energy efficiency are becoming increasingly
important, we are seeing companies move towards designing their own
application-specific hardware accelerators tailored to their workloads instead
of relying on general-purpose \glspl{CPU} or \glspl{GPU}.  By specialising the
hardware to the application, the hardware can be optimised further than general
purpose processors, unlocking better performance while often using less power.
Apple and Google, for example, are integrating machine learning accelerators
into consumer hardware to allow models to run more efficiently than if they used
the \gls{CPU} or \gls{GPU}~\cite{apple22_dtane, gupta23_gtg}.  Machine learning
is an example of an application that benefits greatly from having dedicated and
specialised hardware accelerators designed for
it~\cite{reuther20_survey_machin_learn_accel}.

Alas, designing these accelerators can be a tedious and error-prone process.
Hardware is normally designed using a \gls{HDL} such as Verilog or VHDL, which
operates at the register-transfer level where the hardware needs to be described
manually.  As the complexity of hardware designs increases, designing hardware
at this level becomes increasingly difficult, because the low-level description
of the hardware makes it time-consuming and expensive to thoroughly test to
ensure that it behaves as expected.  An attractive alternative is
\emph{\gls{HLS}}, where hardware designs are automatically compiled from
software written in a high-level language like C.  This way, hardware design can
benefit from mature software development tools while working on the general
functionality of the hardware, and then use a modern \gls{HLS} tools such as
\legup{}~\cite{canis13_l}, Vitis HLS~\cite{amd23_vitis_high_synth}, Intel
i++~\cite{intel20_hsc}, Stratus HLS~\cite{roane23_autom_hw_sw_co_desig} or Bambu
HLS~\cite{pilato13_bambu} to produce the register-transfer level description.
These \gls{HLS} tools promise designs with comparable performance and
energy-efficiency to those hand-written in an
\gls{HDL}~\cite{homsirikamol14_can, gauthier20_high_level_synth,
  pelcat16_desig_hdl}.  This reduces the time needed to design new hardware
accelerators and as the design is performed at a higher level, the process
should also be less error-prone.

\paragraph{Verifying the functionality of HLS designs} Compared to software, it
is even more important to ensure that hardware functions as it is supposed to,
because once the hardware has been taped-out into an \gls{ASIC}, it becomes
impossible to properly fix the issue except through workarounds in software.
This may come at a great cost in terms of energy usage and the performance of
the system compared to fixing the issue in hardware
itself~\cite{herzog21_price_meltd_spect,
  bowen20_perfor_cost_softw_based_secur_mitig}.  These hardware faults can also
often be exploited and can be hard to detect, even using state-of-the-art
hardware verification methodologies~\cite{dessouky19_hardf}, either because the
correctness properties themselves can be hard to express, or because the
state-space that needs to be explored by the tools is too large.

\Gls{HLS} should simplify the process of verifying the functionality of the
hardware design.  Verifying designs at the register-transfer level requires
large engineering efforts because of the level of detail and the size of the
design.  Even testing such large designs can be problematic, because the size of
the design often means one cannot simulate running the hardware for more than a
few seconds.  Instead, \gls{HLS} moves the verification of the functionality of
the design to a higher level, where less detail is exposed, making it possible
for software tools to reason about the behaviour of the program
instead. Although a recent survey by \textcite{lahti19_are_we_there_yet}
describes that verification remains a time-consuming part of the design process
even with the use of \gls{HLS}, it finds that in general it still reduced the
verification effort by half.

Unfortunately, there are reasons to doubt that \gls{HLS} tools actually preserve
the behaviour of the design, increasing the chance of there being exploitable
hardware faults in the resulting accelerator, and making verification at the
level of the high-level language less useful.  Some of these reasons are
general: \gls{HLS} tools are large pieces of software, they perform a series of
complex analyses and transformations, and the \gls{HDL} output they produce has
superficial syntactic similarities to a software language but a subtly different
semantics.  Other reasons are more specific: for instance, Vivado HLS has been
shown to apply pipelining optimisations incorrectly%
\footnote{\url{https://support.xilinx.com/s/question/0D52E00006jt7LfSAI/crtl-cosimulation-failed-caused-by-pragma-hls-pipeline}} %
%\url{https://forums.xilinx.com/t5/High-Level-Synthesis-HLS/BUG-report-HLS-chooses-the-wrong-II-and-the-result-is-wrong/m-p/1070935 (this report may have conveniently been removed from the forum).
or to silently generate wrong code should the programmer stray outside the
fragment of C that it supports.%
\footnote{\url{https://support.xilinx.com/s/question/0D52E00006hpMZSSA2/pointer-synthesis-in-vivado-hls-v201}}%
\textsuperscript{,}%
\footnote{\url{https://docs.xilinx.com/r/en-US/ug1399-vitis-hls/Pointer-Limitations}}
Meanwhile, \textcite{lidbury15_many_core_compil_fuzzin} had to abandon their
attempt to fuzz-test Altera's (now Intel's) OpenCL to hardware compiler since it
\enquote{either crashed or emitted an internal compiler error} on many of their
test inputs.  More recently, \textcite{herklotz21_esrhlst} fuzz-tested three
commercial \gls{HLS} tools using
Csmith~\cite{yang11_findin_under_bugs_c_compil}, and despite restricting the
generated programs to the C fragment explicitly supported by all the tools, they
still found that on average 2.5\% of test-cases were compiled to designs that
behaved incorrectly.

\paragraph{Existing workarounds}

Aware of the reliability shortcomings of \gls{HLS} tools, hardware designers
routinely check the generated hardware for functional correctness.  This is
commonly done by simulating the generated design against a large test-bench.
But unless the test-bench covers all inputs exhaustively -- which is often
infeasible -- there is a risk that bugs remain.

One alternative is to use \emph{\gls{translation
    validation}}~\cite{pnueli98_trans} to prove equivalence between the input
program and the output design. \Gls{translation validation} has been
successfully applied to several \gls{HLS} optimisations~\cite{kim04_autom_fsmd,
  karfa06_formal_verif_method_sched_high_synth,
  chouksey20_verif_sched_condit_behav_high_level_synth,
  banerjee14_verif_code_motion_techn_using_value_propag,
  chouksey19_trans_valid_code_motion_trans_invol_loops}.  Nevertheless, it is an
expensive task, especially for large designs, and it must be repeated every time
the compiler is invoked.  For example, the translation validation for Catapult
C~\cite{mentor20_catap_high_level_synth} may require several rounds of expert
\enquote{adjustments}~\cite[p.~3]{chauhan20_formal_ensur_equiv_c_rtl} to the
input C program before validation succeeds. And even when it succeeds,
translation validation does not provide watertight guarantees unless the
validator itself has been mechanically proven
correct~\cite[e.g.][]{tristan08_formal_verif_trans_valid}, which has not been
the case in \gls{HLS} tools to date.

My position is that none of the above workarounds are necessary if the \gls{HLS}
tool can simply be trusted to work correctly.  This dissertation explores the
implementation of a mechanically verified and optimising \gls{HLS} tool built on
the \compcert{} verified C compiler~\cite{leroy06_formal_certif_compil_back_end,
  leroy09_formal_verif_realis_compil, leroy16_cfvoc}.  The main thesis of this
dissertation is therefore the following:

\begin{samepage}
  \begin{quote}
    \textbf{Thesis}\quad A realistic and optimising high-level synthesis tool
    can be proven correct using an interactive theorem prover, guaranteeing the
    correctness of the hardware while also remaining practical and efficient.
  \end{quote}
\end{samepage}

\section{Research Contributions}%
\label{sec:intro:research-contributions}

The main contributions of this dissertation is \vericert{}, a formally verified
and optimising \gls{HLS} tool.  \vericert{} is written in the Coq theorem prover
and comes with a machine-checked proof that any output design it produces always
has the same behaviour as the input C program.  \vericert{} is automatically
extracted to an OCaml program from Coq, which ensures that the object of the
proof is the same as the implementation of the tool.  \vericert{} is built by
extending the \compcert{} verified C compiler with a new hardware-specific
intermediate language and a Verilog back end.  It supports many C constructs,
including integer operations, function calls (which are all inlined), local
arrays, structs, unions, and general control-flow statements, but currently
excludes support for case statements, function pointers, recursive function
calls, non-32-bit integers, floats, and global variables.  The main research
contributions of \vericert{} are the following:

\begin{description}
\item[Formulate overall correctness theorem with Verilog semantics] First, I
  state the correctness theorem of \vericert{} with respect to an existing
  semantics for Verilog due to \textcite{lööw19_proof_trans_veril_devel_hol}.
  The key challenge here involved integrating the hardware semantics within
  CompCert's model of computation and calling convention.  This required
  specifying the external module interface used to interact with the final
  hardware produced by Vericert, for example specifying how the hardware can be
  reset, and how the final return value is extracted.  Another challenge was
  extending the Verilog semantics with support for arrays, which is necessary to
  model hardware memory interfaces.  Lastly, one particular difficulty that had
  to be overcome is proving that the function stack could be modelled by this
  finite Verilog array.

\item[First mechanisation of general if-conversion] CompCert does already
  perform limited if-conversion, removing branches that contain a single
  instruction and replacing them with a conditional move instruction, because
  predicated instructions are unsupported.  I describe the formalisation of a
  general if-conversion transformation in CompCert used to generate hyperblocks,
  which are sequences of possibly branching predicated instructions, where the
  only incoming edges are to the start of the block.  The key challenge was to
  generalise the if-conversion pass so that any external unverified heuristic
  could be used to inline blocks, while keeping the correctness proof
  conceptually simple.  It is also flexible enough to allow for light loop
  transformations like loop unrolling and loop peeling.

\item[Formal verification of hyperblock scheduling] Next, I present a verified
  implementation of hyperblock scheduling, a critical optimisation for any
  \gls{HLS} tool, taking advantage of the parallel nature of the hardware that
  is generated.  I implement and validate the \gls{SDC} scheduling
  algorithm~\cite{cong06_sdc}, which is the base of the scheduling algorithm
  used by most \gls{HLS} tools.  Prior work verifying scheduling algorithms in
  CompCert~\cite{tristan08_formal_verif_trans_valid,
    six22_formal_verif_super_sched} either were not general enough, being unable
  to schedule two branches of an if-statement together, or were inefficient
  because of unnecessary duplication when checking the correctness of the
  schedule.  Instead, the key insight for this contribution is that predicates
  can be used to share otherwise duplicate expressions along different paths
  through the program.

\item[SAT and SMT solvers for translation validation in CompCert] I also present
  a novel use of a \gls{SAT} solver and a three-valued logic solver, implemented
  using an \gls{SMT} solver, during translation validation to reason about the
  equivalence of functions before and after the scheduling transformations.  The
  key challenge here is integrating an existing \gls{SMT} proof checker, meant
  for assisting with interactive Coq proofs, and using it as a checker that can
  be used by the compiler at runtime to check that, for example, a three-valued
  predicate always holds.  This can be used as a general validator for any
  transformation pass where the correctness depends on dynamically generated
  properties expressible in three-valued logic that need to be checked.

%\item We also describe how the scheduled instructions are then converted into
%  Verilog through a number of verified transformations, by first destroying the
%  hyperblock structure, then building up a \gls{FSMD},

\item[Evaluation of Vericert on PolyBench/C] Finally, I evaluate different
  versions of Vericert against the state-of-the-art open source and unverified
  \gls{HLS} tool Bambu HLS~\cite{pilato13_bambu} on a standard C benchmark suite
  called PolyBench/C.  One might expect a fully verified tool to perform
  significantly worse than a more optimised, unverified tool, however, we show
  that Vericert produces designs that have around the same cycle count as Bambu
  without optimisations, with a slightly worse maximum clock speed, leading to
  an overall execution speed of around $1.6\times$ that of Bambu designs.
  However, when comparing against optimised Bambu, Vericert is $3.6\times$
  slower, which can be explained by the extensive loop optimisations present in
  Bambu.
\end{description}

\paragraph{Companion material}
\vericert{} is fully open source and available on GitHub at:

\begin{center}
  \url{https://github.com/ymherklotz/vericert}
\end{center}

A snapshot of the \vericert{} development is also available in a Zenodo
repository~\cite{herklotz24_v}.

\section{Dissertation Outline}

This dissertation is organised into the following chapters.

\begin{description}
\item[\Cref{sec:background}] provides background for the rest of the
  dissertation and also discusses related work around verification of high-level
  synthesis.
\item[\Cref{sec:introduction-to-vericert}] introduces Vericert itself, giving an
  overview of how it is structured, as well as what kind of transformations are
  performed.  Design choices made during the development of Vericert are also
  described and compared against other possible approaches.
\item[\Cref{sec:trusted-computing-base}] then gives a summary of the trusted
  computing base in Vericert, describing the Verilog semantics and the final
  correctness theorem.
\item[\Cref{sec:hyperblock-scheduling}] then describes the front end of
  Vericert, which hooks into the middle end of \gls{CompCert}.  This chapter
  describes the implementation of hyperblock scheduling.
\item[\Cref{sec:hardware-generation}] then describes how the hyperblocks
  optimised by the scheduling algorithm are then turned into a hardware design
  in Verilog.
\item[\Cref{sec:evaluation}] evaluates different versions of Vericert in a
  number of ways on certain metrics comparing it against Bambu.
\item[\Cref{sec:conclusion}] finally gives a description of the limitations of
  Vericert as well as a discussion of the formalisation.  In addition to that,
  many possible future directions are discussed.
\end{description}

\section{Publications}

The research in this dissertation has also been presented in the following three
publications.

\begin{description}

\item[FCCM 2021] This first paper evaluates the reliability of \gls{HLS} tools
  and motivates the need for a more reliable \gls{HLS} tool, as well as a more
  robust verification flow for \gls{HLS} designs.  This paper is described in
  \cref{sec:itv:unreliability-hls}.

  \printpublication{herklotz21_esrhlst}.

\item[OOPSLA 2021] Next, we introduce Vericert and describe an initial
  translation from C to Verilog using \gls{CompCert}, without optimisations.
  This article is the basis for the dissertation, making up parts of
  \cref{sec:introduction-to-vericert,sec:trusted-computing-base,sec:hardware-generation}.

  \printpublication{herklotz21_fvhls}.

\item[PLDI 2024 (under submission)] Finally, an article describing a critical
  optimisation in the \gls{HLS} flow called \gls{hyperblock scheduling} is under
  submission.  This preprint underpins \cref{sec:hyperblock-scheduling}.

  \printpublication{herklotz24_hsvhls}.

\end{description}

The following publications did not directly contribute to the dissertation.

\begin{description}
\item[FPGA 2020] This paper describes bugs that were found in hardware synthesis
  tools by generating random, deterministic hardware designs.

  \printpublication{herklotz20_fubfst}.
\item[FCCM 2022] This short paper describes an implementation of function calls
  in Vericert allowing function bodies to be shared between calls.

  \printpublication{pardalos22_rsvhls}.
\item[CPP 2023] Finally, this paper described an implementation of a
  control-flow based semantics for gated-SSA in CompCertSSA, a first step
  towards a pure data-flow intermediate language in CompCert.

  \printpublication{herklotz23_msgssa}.
\end{description}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% TeX-engine: luatex
%%% End:
