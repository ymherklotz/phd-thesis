\chapter{Introduction}%
\label{sec:introduction}

%% Motivation for why HLS might be needed

% \JW{A few high-level comments: \begin{enumerate} \item Create more tension
%   from the start by making the reader doubt whether existing HLS tools are
%   trustworthy. \item The intro currently draws quite a bit of motivation from
%   Lidbury et al. 2015, but we should also now lean on our FPGA submission
%   too. \item I wonder whether the paragraph `To mitigate the problems...'
%   should be demoted to a `related work' discussion (perhaps as a subsection
%   towards the end of the introduction). It outlines (and nicely dismisses)
%   some existing attempts to tackle the problem, which is certainly useful
%   motivation for your work, especially for readers already familiar with HLS,
%   but I feel that it's not really on the critical path for understanding the
%   paper.\end{enumerate}}

% \NR{I couldn't have subsections in comments so I have appended my writing to
% the bottom of this file.}\YH{The original intro is in the archive, we can
% maybe merge them in the future a bit.}

As latency, throughput, and energy efficiency are becoming increasingly
important, we are seeing companies move towards designing their own
application-specific hardware accelerators tailored to their workloads instead
of relying on general purpose \glspl{CPU} or \glspl{GPU}.  By specialising the
hardware to the application, the hardware can be optimised further than general
purpose processors, unlocking better performance while often using less power.
Apple and Google, for example, are integrating machine learning accelerators
into consumer hardware to allow models to run more efficiently than if they used
the \gls{CPU} or \gls{GPU}.  Machine learning is an example of an application
that benefits greatly from having dedicated and specialised hardware
accelerators designed for it~\cite{reuther20_survey_machin_learn_accel}.

Alas, designing these accelerators can be a tedious and error-prone process.
Designing hardware is normally done using a \gls{HDL} such as Verilog or VHDL,
which operate at the register transfer level where the hardware needs to be
described manually.  As the complexity of these hardware designs increases,
designing hardware at this level becomes increasingly difficult, as the
low-level description of the hardware can be difficult to test to ensure that it
behaves as expected.  An attractive alternative is \emph{\gls{HLS}}, where
hardware designs are automatically compiled from software written in a
high-level language like C.  This way, hardware design can benefit from mature
software development tools while working on the general functionality of the
hardware design, and then use a modern \gls{HLS} tools such as
\legup{}~\cite{canis13_l}, Vitis HLS~\cite{amd23_vitis_high_synth}, Intel
i++~\cite{intel20_hsc}, Stratus HLS~\cite{roane23_autom_hw_sw_co_desig} and
Bambu HLS~\cite{pilato13_bambu} to produce the hardware design at the register
transfer level.  These \gls{HLS} tools promise designs with comparable
performance and energy-efficiency to those hand-written in an
\gls{HDL}~\cite{homsirikamol14_can, gauthier20_high_level_synth,
  pelcat16_desig_hdl}.  This reduces the time needed to design new hardware
accelerators and as the design is performed at a higher level, this should also
make the process less error-prone.

\paragraph{Verifying the functionality of HLS designs} \Gls{HLS} should also
simplify the process of verifying the functionality of the hardware design.
Verifying designs at the register transfer level requires large engineering
efforts because of the level of detail and the size of the design.  Even testing
such large designs can be problematic, because the size of the design often
means one cannot simulate running the hardware for more than a few seconds.
Instead, \gls{HLS} moves the verification of the functionality of the design to
a higher-level, where less detail is exposed, making it possible for software
tools to reason about the behaviour of the program instead. A recent survey by
\textcite{lahti19_are_we_there_yet} describes that verification is still a
time-consuming part of the design process though, even with the use of
\gls{HLS}, however, that in general it still reduced the verification effort by
half.  Most papers that were surveyed did not mention verification of designs
though and it therefore still remains an underexplored area in \gls{HLS}
research.

% \YH{TODO: Talk about the history of HLS to motivate it better.}

To make matters worse, there are reasons to doubt that \gls{HLS} tools actually
\emph{do} always preserve equivalence, increasing the chance of there being
exploitable hardware faults in the resulting accelerator, and making
verification at the level of the high-level language less effective.  Some of
these reasons are general: \gls{HLS} tools are large pieces of software, they
perform a series of complex analyses and transformations, and the \gls{HDL}
output they produce has superficial syntactic similarities to a software
language but a subtly different semantics.  Other reasons are more specific: for
instance, Vivado HLS has been shown to apply pipelining optimisations
incorrectly%
\footnote{\url{https://forums.xilinx.com/t5/High-Level-Synthesis-HLS/BUG-report-HLS-chooses-the-wrong-II-and-the-result-is-wrong/m-p/1070935}
(this report may have conveniently been removed from the forum).}  or to
silently generate wrong code should the programmer stray outside the fragment of
C that it supports.%
\footnote{\url{https://support.xilinx.com/s/question/0D52E00006hpMZSSA2/pointer-synthesis-in-vivado-hls-v201}}%
\textsuperscript{,}%
\footnote{\url{https://docs.xilinx.com/r/en-US/ug1399-vitis-hls/Pointer-Limitations}}
Meanwhile, \textcite{lidbury15_many_core_compil_fuzzin} had to abandon their
attempt to fuzz-test Altera's (now Intel's) OpenCL compiler since it
\enquote{either crashed or emitted an internal compiler error} on so many of
their test inputs.  More recently, \textcite{herklotz21_esrhlst} fuzz-tested
three commercial \gls{HLS} tools using
Csmith~\cite{yang11_findin_under_bugs_c_compil}, and despite restricting the
generated programs to the C fragment explicitly supported by all the tools, they
still found that on average 2.5\% of test-cases were compiled to designs that
behaved incorrectly.

Compared to software, it is necessary to ensure that hardware functions as it is
supposed to, because once the hardware has been taped-out into an \gls{ASIC},
there is no way to properly fix the issue except to work around it in software.
This may come at a great cost compared to fixing the issue in hardware itself on
both the energy usage and the performance of the
system~\cite{herzog21_price_meltd_spect,bowen20_perfor_cost_softw_based_secur_mitig}.
These hardware faults can also often be exploited and can be hard to detect,
even using state-of-the-art hardware verification
methodologies~\cite{dessouky19_hardf}, sometimes because the correctness
properties themselves can be hard to express, or because the state-space that
needs to be explored by the tools is too large.

\paragraph{Existing workarounds}

Aware of the reliability shortcomings of \gls{HLS} tools, hardware designers
routinely check the generated hardware for functional correctness.  This is
commonly done by simulating the generated design against a large test-bench.
But unless the test-bench covers all inputs exhaustively -- which is often
infeasible -- there is a risk that bugs remain.

One alternative is to use \emph{\gls{translation
    validation}}~\cite{pnueli98_trans} to prove equivalence between the input
program and the output design. \Gls{translation validation} has been
successfully applied to several \gls{HLS} optimisations~\cite{kim04_autom_fsmd,
  karfa06_formal_verif_method_sched_high_synth,
  chouksey20_verif_sched_condit_behav_high_level_synth,
  banerjee14_verif_code_motion_techn_using_value_propag,
  chouksey19_trans_valid_code_motion_trans_invol_loops}.  Nevertheless, it is an
expensive task, especially for large designs, and it must be repeated every time
the compiler is invoked.  For example, the translation validation for Catapult
C~\cite{mentor20_catap_high_level_synth} may require several rounds of expert
\enquote{adjustments}~\cite[p.~3]{chauhan20_formal_ensur_equiv_c_rtl} to the
input C program before validation succeeds. And even when it succeeds,
translation validation does not provide watertight guarantees unless the
validator itself has been mechanically proven
correct~\cite[e.g.][]{tristan08_formal_verif_trans_valid}, which has not been
the case in \gls{HLS} tools to date.

%\JW{Having nuanced our discussion of TV above, I feel like the text below
%belongs more in a `future directions' paragraph at the end of the paper than in
%an `existing workarounds' section.} Nevertheless translation validation has
%many benefits in a mechanically verified setting as well to simplify the proofs
%to depend less on the exact implementation of the optimisation.  It has also
%already been used to prove certain passes in \compcert{} correct.  The main
%issue with the translation validation methods applied in HLS tools normally is
%that they \NR{\sout{try and}} generalise over all optimisations that are
%performed and \NR{\sout{try to}} compare the generated hardware directly to the
%high-level input. \NR{The word input used here again.}  However, verification
%requires optimisations to be proven correct incrementally and separately,
%making translation validation more viable.  By proving specific optimisations
%with a constraint on the kinds of transformations it can perform, it is
%possible to write a verified validator that is also believed to be complete and
%should not fail on valid transformations unless bugs are present.

The main thesis of this dissertation is therefore the following.

\begin{samepage}
  \begin{quote}
    \textbf{Thesis}\quad A realistic and optimising high-level synthesis tool
    can be proven correct using an interactive theorem prover, guaranteeing the
    correctness of the hardware while also remaining practical and efficient.
  \end{quote}
\end{samepage}

Our position is that none of the above workarounds are necessary if the
\gls{HLS} tool can simply be trusted to work correctly.  This dissertation
explores the implementation of a mechanically verified and optimising \gls{HLS}
tool built on the \compcert{} verified C
compiler~\cite{leroy06_formal_certif_compil_back_end,leroy09_formal_verif_realis_compil,leroy16_cfvoc}.

% \NR{Perhaps, we can add something like: `... and our efforts are the first
% step towards building this trust within HLS
% tools.'.} %JW: I think that would be over-egging the cake.


\section{Research Contributions}%
\label{sec:intro:research-contributions}

The main contributions of this dissertation is \vericert{}, a formally verified
and optimising \gls{HLS} tool.  \vericert{} is written in the Coq theorem prover
and we have proved that any output design it produces always has the same
behaviour as the input C program.  \vericert{} is automatically extracted to an
OCaml program from Coq, which ensures that the object of the proof is the same
as the implementation of the tool.  \vericert{} is built by extending the
\compcert{} verified C compiler with a new hardware-specific intermediate
language and a Verilog back end.  It supports many C constructs, including
integer operations, function calls (which are all inlined), local arrays,
structs, unions, and general control-flow statements, but currently excludes
support for case statements, function pointers, recursive function calls,
non-32-bit integers, floats, and global variables.  The main research
contributions of \vericert{} are the following:

\begin{description}
\item[Formulate overall correctness theorem with Verilog semantics] First, we
  state the correctness theorem of \vericert{} with respect to an existing
  semantics for Verilog due to \textcite{lööw19_proof_trans_veril_devel_hol}. In
  \cref{sec:trusted-computing-base}, we describe how we extended this semantics
  to make it a suitable \gls{HLS} target.  We also describe how the Verilog
  semantics is integrated into \compcert{}'s language execution model and its
  framework for performing simulation proofs.  Finally, we describe how a subset
  of the \gls{CompCert} memory model is mapped into Verilog arrays.

\item[General if-conversion transformation] We describe a general if-conversion
  transformation used to generate hyperblocks, which are sequences of possibly
  branching instructions without back edges.  This if-conversion transformation
  is split into a number of transformations that simplify the overall proof.  In
  addition to that, it is flexible and even allows for light loop
  transformations like loop unrolling.

\item[Formal verification of hyperblock scheduling] Next, we present a verified
  implementation of hyperblock scheduling, a critical optimisation for any
  \gls{HLS} tool, taking advantage of the parallel nature of the hardware that
  is generated.  We implement and validate the \gls{SDC} scheduling
  algorithm~\cite{cong06_sdc}, which is the base of the scheduling algorithm
  used by most \gls{HLS} tools.

\item[SAT and SMT solvers for translation validation in CompCert] We also
  present a novel use of a SAT and SMT solver during translation validation to
  reason about the equivalence of functions before and after the scheduling
  transformations.

%\item We also describe how the scheduled instructions are then converted into
%  Verilog through a number of verified transformations, by first destroying the
%  hyperblock structure, then building up a \gls{FSMD},

\item[Evaluation of Vericert on PolyBench/C] Finally, we evaluate different
  versions of Vericert against the state-of-the-art open source \gls{HLS} tool
  Bambu HLS~\cite{pilato13_bambu}, showing that it is approximately as
  performant as Bambu HLS without optimisations, but 3$\times$ slower than
  optimised Bambu HLS.
\end{description}

\paragraph{Companion material}
\vericert{} is fully open source and available on GitHub at
\url{https://github.com/ymherklotz/vericert}. A snapshot of the \vericert{}
development is also available in a Zenodo
repository~\cite{herklotz21_v}\YH{TODO: Update the Zenodo link}.

\section{Thesis Outline}

This thesis is organised into the following chapters.

\begin{description}
\item[\Cref{sec:background}] provides background for the rest of the thesis and
  also discusses related work around verification of high-level synthesis.
  First, \cref{sec:bg:hls} introduces high-level synthesis and describes the
  main critical optimisations such as scheduling and loop pipelining. Next,
  traditional verification workflows for \gls{HLS} are described in
  \cref{sec:bg:unmechanised-verification-of-hls}. This is then followed by a
  description of \gls{CompCert}, the formally verified C compiler that Vericert
  is built on is also introduced and its correctness proof explained in
  \cref{sec:bg:compcert}.
\item[\Cref{sec:introduction-to-vericert}] introduces Vericert itself, giving an
  overview of how it is structured, as well as what kind of transformations are
  performed.  Design choices made during the development of Vericert are also
  described and compared against other possible approaches.
\item[\Cref{sec:trusted-computing-base}] then gives a summary of the trusted
  computing base in Vericert, describing the Verilog semantics and the final
  correctness theorem.
\item[\Cref{sec:hyperblock-scheduling}] then describes the front end of
  Vericert, which hooks into the middle end of \gls{CompCert}.  This chapter
  describes the implementation of hyperblock scheduling.  First,
  \cref{sec:hs:overview} gives an overview of the scheduling optimisation, then
  \cref{sec:hs:rtlblockdef} introduces the new intermediate languages used for
  the scheduling transformation.  \Cref{sec:hs:if-conversion} then describes
  hyperblock construction using if-conversion followed by
  \cref{sec:hs:implementing-scheduling,sec:hs:verifying-scheduling,sec:hs:overview-validator-correctness-proof}
  describing the implementation, validation and verification of the actual
  hyperblock transformation.  Finally,
  \cref{sec:hs:efficient-smt-solver-validation} describes the use of a validated
  SMT solver as part of the hyperblock scheduling correctness proof.
\item[\Cref{sec:hardware-generation}] then describes how the hyperblocks
  optimised by the scheduling algorithm are then turned into a hardware design
  in Verilog.  First, \cref{sec:hg:hyperblock-destruction} describes the
  hyperblock destruction pass that removes some of the block structure of the
  code.  Then, \cref{sec:hg:htl-generation} describes the generation of a state
  machine from the code, which is closer to the final structure of the hardware.
  Next, \cref{sec:hg:bram-insertion} describes the generation of a proper memory
  so that this can be implemented more efficiently in hardware.
  \Cref{sec:hg:register-forward-substitution} then describes the transformation
  of a more sequential description of the hardware into a parallel description
  to make it more robust when turned into hardware.  Finally,
  \cref{sec:hg:verilog-generation} describes the generation of Verilog.
\item[\Cref{sec:evaluation}] evaluates Vericert in a number of ways on certain
  metrics comparing it against Bambu.
\item[\Cref{sec:conclusion}] finally gives a description of the limitations of
  Vericert as well as a discussion of the formalisation.  In addition to that,
  many possible future directions are explored.
\end{description}

\section{Publications}

This thesis is made up of the following three publications.

\begin{description}

\item[FCCM 2021] This first paper evaluates the reliability of \gls{HLS} tools
  and motivates the need for a more reliable \gls{HLS} tool, as well as a more
  robust verification flow for \gls{HLS} designs.

  \printpublication{herklotz21_esrhlst}.

\item[OOPSLA 2021] Next, we introduce Vericert and describe an initial
  translation from C to Verilog using \gls{CompCert}, without optimisations.
  This article is the basis for the thesis, making up parts of
  \ref{sec:introduction-to-vericert,sec:trusted-computing-base,sec:hardware-generation}.

  \printpublication{herklotz21_fvhls}.

\item[PLDI 2024 (under submission)] Finally, an article describing a critical
  optimisation in the \gls{HLS} flow called \gls{hyperblock scheduling} is under
  submission.  This preprint underpins \cref{sec:hyperblock-scheduling}.

  \printpublication{herklotz24_hsvhls}.

\end{description}

The following publications did not directly contribute to the thesis.

\begin{description}
\item[FPGA 2020] \printpublication{herklotz20_fubfst}.
\item[FCCM 2022] \printpublication{pardalos22_rsvhls}.
\item[CPP 2023] \printpublication{herklotz23_msgssa}.
\end{description}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% TeX-engine: luatex
%%% End:
