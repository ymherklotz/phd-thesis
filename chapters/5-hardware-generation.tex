\chapter{Hardware Generation}

Until now the representation of the program has still been in the form of a
software program, with virtual, infinite registers, a program counter, as well
as a rich but abstract memory model.  This representation needs to be
transformed into a more suitable representation on which hardware specific
transformations can applied, and which is closer to th structure of the final
Verilog design.  The main transformation that takes place is converting a
control-flow graph into a state machine with data-path representation, which is
also the structure of the final design.  There are various steps involved in
this refinement because of the large gap between control-flow graph semantics
and state machine semantics.  In addition to that, additional components, such
as an implementation of a memory that can be efficiently implemented in
hardware, need to be added to the hardware to produce a useful design.  Finally,
until now programs have only been executing sequentially, whereas to produce the
final hardware one will have to transform the sequential execution of operations
within each state into parallel assignments.

This chapter describes the hardware generation process, starting from \rtlpar{}
and producing a final Verilog design.  \Cref{sec:hg:state-partitioning}
describes the first step in the transformation which separates each sequential
block within a state in \rtlpar{} into separate states that can be addressed
using the program counter.  This matches addressing that the state register
would have to do in the hardware design. Next, \cref{sec:hg:htl-generation}
describes the generation of HTL, an intermediate language representing the
execution of a state machine.  This performs the main transformation from a
software representation of the program into hardware, making the execution of
the program more explicit in the design itself instead of as part of the
semantics.  \Cref{sec:hg:bram-generation} then describes the first
hardware-specific optimisation on the state-machine representation of the
hardware by adding a specification of a \gls{BRAM} to the HTL semantics and
replacing any explicit reads and writes to the array representing memory by
properly formed reads and writes to the \gls{BRAM}.  Until now, updates to
registers have been specified sequentially, so a forward substitution
transformation is describe in \cref{sec:hg:register-forward-substitution} to
parallelise the updates to registers.  Finally, \cref{sec:hg:verilog-generation}
describes the generation of the final Verilog design, which implements the
state-machine that was specified by HTL, in particular implementing the
\gls{BRAM} that was specified.

\section{State Partitioning}%
\label{sec:hg:state-partitioning}

\rtlpar{} is a control-flow graph with nodes mapping to hyperblocks.  This is
useful for the scheduling proof, as each of these hyperblocks can be compared
individually.  However, in the hardware itself, the individual sequential blocks
have to be separated into different states, as within each state the
assignments will be performed in parallel.  This first state partitioning
transformation separates operations that should execute in different clock
cycles into their own locations in the control-flow graph.

\begin{figure}
  \centering
  \begin{tikzpicture}[>=Latex,shorten >=1pt,
    label/.style={circle,draw,fill=white,inner sep=0.4mm,font=\footnotesize},
    bb/.style={align=left, draw=white, fill=black!5}]
    \node[bb] (initial block) {\rtlinline`[ [ [ r1 := r2 ] ]; `\\
                               \rtlinline`  [ [ r3 := r4 ];   `\\
                               \rtlinline`    [ goto 2   ] ] ]`};
    \node[bb, right=4cm of initial block, yshift=1cm] (first transf block)
      {\rtlinline`[ [ r1 := r2 ]; `\\
       \rtlinline`  [ goto 3   ] ]`};
    \node[bb, below=of first transf block] (second transf block)
                               {\rtlinline`  [ [ r3 := r4 ];   `\\
                                \rtlinline`    [ goto 2   ] ]`};
    \node[label] at (initial block.north west) {\texttt{1}};
    \node[label] at (first transf block.north west) {\texttt{1}};
    \node[label] at (second transf block.north west) {\texttt{3}};
    \draw[->,very thick] ($(initial block.east) + (0.5,0)$)
      -- node [below, font=\footnotesize] {state partitioning}
      ($(initial block.east) + (3,0)$);
  \end{tikzpicture}
  \caption{State partitioning transformation splitting up the hyperblock into
    multiple locations.}%
  \label{fig:hg:state-partitioning}
\end{figure}

\Cref{fig:hg:state-partitioning} shows an example state partitioning
transformation, where a new block is added at location \diaglabel{$3$} with the
contents of the second sequential block, and a \rtlinline`goto` instruction is
added to the original block leading to this next block.  Fresh locations for new
blocks are chosen by keeping track of the greatest location in the current
function.

\subsection{Proof of State Partitioning}

The proof of state partitioning is relatively simple using a
\gls{plus-forward-simulation}.  Then, for each input states, there are one or
more output states returned by the state partitioning algorithm that should be
equivalent to the execution of the input state when executed sequentially.

\section{HTL Generation}%
\label{sec:hg:htl-generation}

The most important transformation of an HLS tool is then the generation of a
hardware description from the list of instructions.  Eventually the hardware
design will be described using Verilog, however, to make the transformation more
incremental, we first turn the program represented by a control-flow graph into
a program represented by an \gls{FSMD}.  This section will describe the
\gls{FSMD} language, called HTL, by showing the syntax and semantics of the
language.  Then, the transformation from \rtlsubpar{} to HTL is shown, together
with an overview of its correctness proof.

\subsection{HTL Structure and Semantics}%
\label{sec:hg:htl-structure-and-semantics}

At a high level, HTL is structured like many other \compcert{} languages,
mapping from locations to Verilog statements.  However, contrary to many other
intermediate languages in \compcert{}, HTL does not contain any instructions,
and its semantics use a smaller state to perform the execution.  For example,
the state does not have to contain the program counter because there is an
explicit state register that keeps track of it.

HTL comprises a a lot of metadata pointing to important registers, as well as
containing a map from program locations to Verilog statements.

\begin{figure}
\centering
\begin{tabular}{rr@{~}r@{~}l@{\hspace*{2mm}}l}
  \llabel{registers} & $\reg, \mbox{\rtlinline{r1}}, \mbox{\rtlinline{r2}}, \ldots \in \regtype$ & & & \\
  \llabel{CFG node labels} & $\location \in \locationtype$ & $::=$ & $\mathbb{N}$ & \\
  \llabel{Verilog statements} & $\verilogstmnt \in \verilogstmnttype$ & & & \\
  \llabel{Code} & $\htlcode \in \locationtype \rightarrow \verilogstmnttype$ & & & \\
  \llabel{HTL} & $\htlmodule$ & $::=$ & $\{\ \mathit{params} : \regtype\
                                        \texttt{list}; $ \\
  & & & $\ \ \mathit{datapath} : \locationtype \rightarrow \verilogstmnttype; $ \\
  & & & $\ \ \mathit{entrypoint} : \mathbb{N};$ & \\
  & & & $\ \ \mathit{state} : \regtype;$ & \\
  & & & $\ \ \mathit{stack} : \regtype;$ & \\
  & & & $\ \ \mathit{stack\_size} : \mathbb{N};$ & \\
  & & & $\ \ \mathit{finish},\mathit{return},\mathit{start},\mathit{reset},\mathit{clk} :
        \regtype;$ & \\
  & & & $\ \ \mathit{ram} : \optiontype{\mathit{RAM}};$ & \\
  & & & $\ \ \mathit{order\_wf} : \mathit{state} < \mathit{finish} < \mathit{return}
        < \mathit{stack} < \mathit{reset} < \mathit{clk};$ & \\
  & & & $\ \ \mathit{ram\_wf} : \forall r\ldotp \mathit{ram} = \some{r} \implies
        \mathit{clk} < r.\mathit{raddr}; $ & \\
  & & & $\ \ \mathit{params\_wf} : \forall r \in \mathit{params}\ldotp
        r < \mathit{state} \ \}$
\end{tabular}
\caption{Syntax of HTL.}
\label{fig:hg:htl}
\end{figure}

\subsection{HTL Generation Algorithm}%
\label{sec:hg:htl-generation}

\subsection{HTL Generation Correctness Proof}%
\label{sec:hg:htl-generation-correctness-proof}

%\section{Correctness Proof}\label{sec:proof}

%\JW{That's quite a hard-to-parse section heading; I'd go for something simpler like `Correctness Proof' or `Proving Correctness'}

The proof of correctness of the Verilog back end is quite different from the
usual proofs performed in CompCert, mainly because of the difference in the
memory model and semantic differences between Verilog and CompCert's existing
intermediate languages.

\begin{itemize}
\item As already mentioned in Section~\ref{sec:verilog:memory}, because the
  memory model in our Verilog semantics is finite and concrete, but the CompCert
  memory model is more abstract and infinite with additional bounds, the
  equivalence of these models needs to be proven.  Moreover, our memory is
  word-addressed for efficiency reasons, whereas CompCert's memory is
  byte-addressed.

\item Second, the Verilog semantics operates quite differently to the usual
  intermediate languages in CompCert.  All the CompCert intermediate languages
  use a map from control-flow nodes to instructions.  An instruction can
  therefore be selected using an abstract program pointer. Meanwhile, in the
  Verilog semantics the whole design is executed at every clock cycle, because
  hardware is inherently parallel. The program pointer is part of the design as
  well, not just part of an abstract state. This makes the semantics of Verilog
  simpler, but comparing it to the semantics of 3AC becomes more challenging, as
  one has to map the abstract notion of the state to concrete values in
  registers.
\end{itemize}

Together, these differences mean that translating 3AC directly to Verilog is
infeasible, as the differences in the semantics are too large.  Instead, HTL,
which was introduced in Section~\ref{sec:design}, bridges the gap in the
semantics between the two languages.  HTL still consists of maps, like many of
the other CompCert languages, but each state corresponds to a Verilog statement.

\subsection{Formulating the Correctness Theorem}

The main correctness theorem is analogous to that stated in
\compcert{}~\cite{leroy09_formal_verif_realis_compil}: for all Clight source
programs $C$, if the translation to the target Verilog code succeeds,
$\mathit{Safe}(C)$ holds and the target Verilog has behaviour $B$ when
simulated, then $C$ will have the same behaviour $B$. $\mathit{Safe}(C)$ means
all observable behaviours of $C$ are safe, which can be defined as
$\forall B,\ C \Downarrow B \implies B \in \texttt{Safe}$.  A behaviour is in
\texttt{Safe} if it is either a final state (in the case of convergence) or
divergent, but it cannot `go wrong'. (This means that the source program must
not contain undefined behaviour.) In \compcert{}, a behaviour is also associated
with a trace of I/O events, but since external function calls are not supported
in \vericert{}, this trace will always be empty.

\begin{theorem}
  Whenever the translation from $C$ succeeds and produces Verilog $V$, and all
  observable behaviours of $C$ are safe, then $V$ has behaviour $B$ only if $C$
  has behaviour $B$.
  \begin{equation*}
    \forall C, V, B,\quad \yhfunction{HLS} (C) = \yhconstant{OK} (V) \land \mathit{Safe}(C) \implies (V \Downarrow B \implies C \Downarrow B).
  \end{equation*}
\end{theorem}

Why is this correctness theorem also the right one for HLS? It could be argued
that hardware inherently runs forever and therefore does not produce a
definitive final result.  This would mean that the \compcert{} correctness
theorem would probably be unhelpful with proving hardware correctness, as the
behaviour would always be divergent.  However, in practice, HLS does not
normally produce the top-level of the design that needs to connect to other
components, therefore needing to run forever.  Rather, HLS often produces
smaller components that take an input, execute, and then terminate with an
answer.  To start the execution of the hardware and to signal to the HLS
component that the inputs are ready, the $\mathit{rst}$ signal is set and unset.
Then, once the result is ready, the $\mathit{fin}$ signal is set and the result
value is placed in $\mathit{ret}$.  These signals are also present in the
semantics of execution shown in Fig.~\ref{fig:inference_module}.  The
correctness theorem therefore also uses these signals, and the proof shows that
once the $\mathit{fin}$ flag is set, the value in $\mathit{ret}$ is correct
according to the semantics of Verilog and Clight.  Note that the compiler is
allowed to fail and not produce any output; the correctness theorem only applies
when the translation succeeds.

How can we prove this theorem? First, note that the theorem is a `backwards
simulation' result (every target behaviour must also be a source behaviour),
following the terminology used in the \compcert{}
literature~\cite{leroy09_formal_verif_realis_compil}. The reverse direction
(every source behaviour must also be a target behaviour) is not demanded because
compilers are permitted to resolve any non-determinism present in their source
programs. However, since Clight programs are all deterministic, as are the
Verilog programs in the fragment we consider, we can actually reformulate the
correctness theorem above as a forwards simulation result (following standard
\compcert{} practice), which makes it easier to prove.  To prove this forward
simulation, it suffices to prove forward simulations between each pair of
consecutive intermediate languages, as these results can be composed to prove
the correctness of the whole HLS tool.  The forward simulation from 3AC to HTL
is stated in Lemma~\ref{lemma:htl} (Section~\ref{sec:proof:3ac_htl}), the
forward simulation for the RAM insertion is shown in Lemma~\ref{lemma:htl_ram}
(Section~\ref{sec:proof:ram_insertion}), then the forward simulation between HTL
and Verilog is shown in Lemma~\ref{lemma:verilog}
(Section~\ref{sec:proof:htl_verilog}), and finally, the proof that Verilog is
deterministic is given in Lemma~\ref{lemma:deterministic}
(Section~\ref{sec:proof:deterministic}).

\subsection{Forward Simulation from 3AC to HTL}\label{sec:proof:3ac_htl}

As HTL is quite far removed from 3AC, this first translation is the most
involved and therefore requires a larger proof, because the translation from 3AC
instructions to Verilog statements needs to be proven correct in this step.  In
addition to that, the semantics of HTL are also quite different to the 3AC
semantics. Instead of defining small-step semantics for each construct in
Verilog, the semantics are defined over one clock cycle and mirror the semantics
defined for Verilog.  Lemma~\ref{lemma:htl} shows the result that needs to be
proven in this subsection.

\begin{lemma}[Forward simulation from 3AC to HTL]\label{lemma:htl}
  Writing \texttt{tr\_htl} for the translation from 3AC to HTL, we have:
  \begin{equation*}
    \forall c, h, B \in \texttt{Safe},\quad \yhfunction{tr\_htl} (c) = \yhconstant{OK} (h) \land c \Downarrow B \implies h \Downarrow B.
  \end{equation*}
\end{lemma}

\begin{proof}[Proof sketch]
  We prove this lemma by first establishing a specification of the translation
  function $\yhfunction{tr\_htl}$ that captures its important properties, and
  then splitting the proof into two parts: one to show that the translation
  function does indeed meet its specification, and one to show that the
  specification implies the desired simulation result. This strategy is in
  keeping with standard \compcert{} practice.

  % The forward simulation is then proven by showing that the initial states and
  % final states between the 3AC semantics and HTL semantics match, and then
  % showing that the simulation diagram in Lemma~\ref{lemma:simulation_diagram}
  % holds.
\end{proof}

\subsubsection{From Implementation to Specification}\label{sec:proof:3ac_htl:specification}

%To simplify the proof, instead of using the translation algorithm as an
%assumption, as was done in Lemma~\ref{lemma:htl}, a specification of the
%translation can be constructed instead which contains all the properties that
%are needed to prove the correctness.  For example, for the translation from 3AC
%to HTL,

The specification for the translation of 3AC instructions into HTL data-path and
control logic can be defined by the following predicate:

\begin{equation*}
  \yhfunction{spec\_instr}\ \mathit{fin}\ \mathit{ret}\ \sigma\ \mathit{stk}\ i\ \mathit{data}\ \mathit{control}
\end{equation*}

\noindent Here, the $\mathit{control}$ and $\mathit{data}$ parameters are the
statements that the current 3AC instruction $i$ should translate to. The other
parameters are the special registers defined in
Section~\ref{sec:verilog:integrating}. An example of a rule describing the
translation of an arithmetic/logical operation from 3AC is the following:

\begin{equation*}
  \inferrule[Iop]{\yhfunction{tr\_op}\ \mathit{op}\ \vec{a} = \yhconstant{OK}\ e}{\yhfunction{spec\_instr}\ \mathit{fin}\ \mathit{ret}\ \sigma\ \mathit{stk}\ (\yhconstant{Iop}\ \mathit{op}\ \vec{a}\ d\ n)\ (d\ \yhkeyword{<=}\ e)\ (\sigma\ \yhkeyword{<=}\ n)}
\end{equation*}

\noindent Assuming that the translation of the operator $\mathit{op}$ with
operands $\vec{a}$ is successful and results in expression $e$, the rule
describes how the destination register $d$ is updated to $e$ via a non-blocking
assignment in the data path, and how the program counter $\sigma$ is updated to
point to the next CFG node $n$ via another non-blocking assignment in the
control logic.

In the following lemma, $\yhfunction{spec\_htl}$ is the top-level specification
predicate, which is built using $\yhfunction{spec\_instr}$ at the level of
instructions.

\begin{lemma}\label{lemma:specification}
  If a 3AC program $c$ is translated correctly to an HTL program $h$, then the
  specification of the translation holds.
  \begin{equation*}
    \forall c, h,\quad \yhfunction{tr\_htl} (c) = \yhconstant{OK}(h) \implies \yhfunction{spec\_htl}\ c\ h.
  \end{equation*}
\end{lemma}

%\begin{proof}
%  Follows from the definition of the specification and therefore should match
%  the implementation of the algorithm.
%\end{proof}

\subsubsection{From Specification to Simulation}

To prove that the specification predicate implies the desired forward
simulation, we must first define a relation that matches each 3AC state to an
equivalent HTL state.  This relation also captures the assumptions made about
the 3AC code that we receive from
\compcert{}. % so that these assumptions can be used to prove the translations correct.
These assumptions then have to be proven to always hold assuming the HTL code
was created by the translation algorithm.  Some of the assumptions that need to
be made about the 3AC and HTL code for a pair of states to match are:

\begin{itemize}
\item The 3AC register file $R$ needs to be `less defined' than the HTL register
  map $\Gamma_{r}$ (written $R \le \Gamma_{r}$). This means that all entries
  should be equal to each other, unless a value in $R$ is undefined, in which
  case any value can match it.
\item The RAM values represented by each Verilog array in $\Gamma_{a}$ need to
  match the 3AC function's stack contents, which are part of the memory $M$;
  that is: $M \le \Gamma_{a}$.
\item The state is well formed, which means that the value of the state register
  matches the current value of the program counter; that is:
  $\mathit{pc} = \Gamma_{r}[\sigma]$.
\end{itemize}

We also define the following set $\mathcal{I}$ of invariants that must hold for
the current state to be valid:

\begin{itemize}
\item that all pointers in the program use the stack as a base pointer,
\item that any loads or stores to locations outside of the bounds of the stack
  result in undefined behaviour (and hence we do not need to handle them),
\item that $\mathit{rst}$ and $\mathit{fin}$ are not modified and therefore stay
  at a constant 0 throughout execution, and
\item that the stack frames match.
\end{itemize}

We can now define the simulation diagram for the translation. The 3AC state can
be represented by the tuple $(R,M,\mathit{pc})$, which captures the register
file, memory, and program counter. The HTL state can be represented by the pair
$(\Gamma_{r}, \Gamma_{a})$, which captures the states of all the registers and
arrays in the module.  Finally, $\mathcal{I}$ stands for the other invariants
that need to hold for the states to match.

\begin{lemma}\label{lemma:simulation_diagram}
  Given the 3AC state $(R,M,\mathit{pc})$ and the matching HTL state
  $(\Gamma_{r}, \Gamma_{a})$, assuming one step in the 3AC semantics produces
  state $(R',M',\mathit{pc}')$, there exist one or more steps in the HTL
  semantics that result in matching states $(\Gamma_{r}', \Gamma_{a}')$.  This
  is all under the assumption that the specification $\yhfunction{spec\_{htl}}$
  holds for the translation.

  \begin{center}
    \begin{tikzpicture}
      \begin{scope}
        \node[circle] (s1) at (0,2) {$R, M, \mathit{pc}$};
        \node[circle] (r1) at (10,2) {$\Gamma_{r}, \Gamma_{a}$};
        \node[circle] (s2) at (0,0) {$R', M', \mathit{pc}'$};
        \node[circle] (r2) at (10,0) {$\Gamma_{r}', \Gamma_{a}'$};
        %\node at (6.8,0.75) {+};
        \draw (s1) -- node[above] {$\mathcal{I} \land (R \le \Gamma_{r}) \land (M \le \Gamma_{a}) \land (\mathit{pc} = \Gamma_{r}[\sigma])$} ++ (r1);
        \draw[-{Latex}] ($(s1.south) + (0,0.4)$) -- ($(s2.north) - (0,0.4)$);
        \draw[-{Latex},dashed] ($(r1.south) + (0,0.2)$) to[auto, pos=0.7] node {+} ($(r2.north) - (0,0.2)$);
        \draw[dashed] (s2) -- node[above] {$\mathcal{I} \land (R' \le \Gamma_{r}') \land (M' \le \Gamma_{a}') \land (\mathit{pc}' = \Gamma_{r}'[\sigma])$} ++ (r2);
      \end{scope}
    \end{tikzpicture}
  \end{center}
\end{lemma}

\begin{proof}[Proof sketch]
  This simulation diagram is proven by induction over the operational semantics
  of 3AC, which allows us to find one or more steps in the HTL semantics that
  will produce the same final matching state.
\end{proof}

\section{BRAM Generation}%
\label{sec:hg:bram-generation}

\subsection{BRAM Model Semantics}%
\label{sec:hg:bram-model-semantics}

\subsection{BRAM Generation and Correctness Proof}%
\label{sec:hg:bram-generation-and-correctness-proof}

\subsection{Forward Simulation of RAM Insertion}\label{sec:proof:ram_insertion}

\begin{figure}
  \centering
  \begin{minipage}{1.0\linewidth}
    \begin{gather*}
      \inferrule[Idle]{\Gamma_{\mathrm{r}}[\mathit{r.en}] = \Gamma_{\mathrm{r}}[\mathit{r.u_{en}}]}{((\Gamma_{\mathrm{r}}, \Gamma_{\mathrm{a}}), \Delta, r) \downarrow_{\text{ram}} \Delta}\\
%
      \inferrule[Load]{\Gamma_{\mathrm{r}}[\mathit{r.en}] \ne \Gamma_{\mathrm{r}}[\mathit{r.u_{en}}] \\ \Gamma_{\mathrm{r}}[\mathit{r.wr_{en}}] = 0}{((\Gamma_{\mathrm{r}}, \Gamma_{\mathrm{a}}), (\Delta_{\mathrm{r}}, \Delta_{\mathrm{a}}), r) \downarrow_{\text{ram}} (\Delta_{\mathrm{r}}[\mathit{r.en} \mapsto \mathit{r.u_{en}}, \mathit{r.d_{out}} \mapsto (\Gamma_{\mathrm{a}}[\mathit{r.mem}])[ \mathit{r.addr}]], \Delta_{\mathrm{a}}) }\\
%
      \inferrule[Store]{\Gamma_{\mathrm{r}}[\mathit{r.en}] \ne \Gamma_{\mathrm{r}}[\mathit{r.u_{en}}] \\ \Gamma_{\mathrm{r}}[\mathit{r.wr_{en}}] = 1}{((\Gamma_{\mathrm{r}}, \Gamma_{\mathrm{a}}), (\Delta_{\mathrm{r}}, \Delta_{\mathrm{a}}), r) \downarrow_{\text{ram}} (\Delta_{\mathrm{r}}[\mathit{r.en} \mapsto \mathit{r.u\_en}], \Delta_{\mathrm{a}}[\mathit{r.mem} \mapsto (\Gamma_{\mathrm{a}}[ \mathit{r.mem}])[\mathit{r.addr} \mapsto \mathit{r.d_{in}}]]) }
    \end{gather*}
  \end{minipage}
  \caption{Specification for the memory implementation in HTL, where $r$ is the RAM, which is then implemented by equivalent Verilog code.}\label{fig:htl_ram_spec}
\end{figure}

HTL can only represent a single state machine, so we must model the RAM
abstractly to reason about the correctness of replacing the direct read and
writes to the array by loads and stores to a RAM.  The specification for the RAM
is shown in Fig.~\ref{fig:htl_ram_spec}, which defines how the RAM $r$ will
behave for all the possible combinations of the input signals.

\subsubsection{From Implementation to Specification}

The first step in proving the simulation correct is to build a specification of
the translation algorithm.  There are three possibilities for the transformation
of an instruction. For each Verilog statement in the map at location $i$, the
statement is either a load, a store, or neither. The load or store is translated
to the equivalent representation using the RAM specification and all other
instructions are left intact.  An example of the specification for the
translation of the store instruction is shown below, where $\sigma$ is state
register, $r$ is the RAM, $d$ and $c$ are the input data-path and control logic
maps, and $i$ is the current state. ($n$ is the newly inserted state, which only
applies to the translation of loads.)

\begin{gather*}
  \inferrule[Store Spec]{ d[i] = (r.mem\texttt{[}e_{1}\texttt{]} \texttt{ <= } e_{2}) \\ t = (r.u\_en \texttt{ <= } \neg r.u\_en; r.wr\_en \texttt{ <= } 1; r.d\_in \texttt{ <= } e_{2}; r.addr \texttt{ <= } e_{1})}%
  {\yhfunction{spec\_ram\_tr}\ \sigma\ r\ d\ c\ d[i \mapsto t]\ c\ i\ n}
\end{gather*}

A similar specification is created for the load.  We then also prove that the
implementation of the translation proves that the specification holds.

\subsubsection{From Specification to Simulation}

Another simulation proof is performed to prove that the insertion of the RAM is
semantics preserving.  As in Lemma~\ref{lemma:simulation_diagram}, we require
some invariants that always hold at the start and end of the simulation.  The
invariants needed for the simulation of the RAM insertion are quite different to
the previous ones, so we can define these invariants $\mathcal{I}_{r}$ to be the
following:

\begin{itemize}
\item The association map for arrays $\Gamma_{a}$ always needs to have the same
  arrays present, and these arrays should never change in size.
\item The RAM should always be disabled at the start and the end of each
  simulation step. (This is why self-disabling RAM is needed.)
\end{itemize}

The other invariants and assumptions for defining two matching states in HTL are
quite similar to the simulation performed in
Lemma~\ref{lemma:simulation_diagram}, such as ensuring that the states have the
same value, and that the values in the registers are less defined.  In
particular, the less defined relation matches up all the registers, except for
the new registers introduced by the RAM.

\begin{lemma}[Forward simulation from HTL to HTL after inserting the RAM]\label{lemma:htl_ram}
  Given an HTL program, the forward-simulation relation should hold after
  inserting the RAM and wiring the load, store, and control signals.

  \begin{align*}
    \forall h, h', B \in \texttt{Safe},\quad \yhfunction{tr\_ram\_ins}(h) = h' \land h \Downarrow B \implies h' \Downarrow B.
  \end{align*}
\end{lemma}

\section{Register Forward Substitution}%
\label{sec:hg:register-forward-substitution}

\subsection{Forward Substitution Correctness Proof}%
\label{sec:hg:forward-substitution-correctness-proof}

\section{Verilog Generation}%
\label{sec:hg:verilog-generation}

\subsection{Forward Simulation from HTL to Verilog}%
\label{sec:proof:htl_verilog}

The HTL-to-Verilog simulation is conceptually simple, as the only transformation
is from the map representation of the code to the case-statement representation.
The proof is more involved, as the semantics of a map structure is quite
different to that of the case-statement to which it is converted.

%\YH{Maybe want to split this up into two lemmas?  One which states the proof about the map property of uniqueness of keys, and another proving the final theorem?}
\begin{lemma}[Forward simulation from HTL to Verilog]\label{lemma:verilog}
  In the following, we write $\yhfunction{tr\_verilog}$ for the translation from
  HTL to Verilog. (Note that this translation cannot fail, so we do not need the
  \yhconstant{OK} constructor here.)
  \begin{align*}
    \forall h, V, B \in \texttt{Safe},\quad \yhfunction{tr\_verilog} (h) = V \land h \Downarrow B \implies V \Downarrow B.
  \end{align*}
\end{lemma}

\begin{proof}[Proof sketch]
  The translation from maps to case-statements is done by turning each node of
  the tree into a case-expression containing the same statements.  The main
  difficulty is that a random-access structure is being transformed into an
  inductive structure where a certain number of constructors need to be called
  to get to the correct case.
  % \JW{I would chop from here.}\YH{Looks good to me.}  The proof of the
  % translation from maps to case-statements follows by induction over the list
  % of elements in the map and the fact that each key will be unique.  In
  % addition to that, the statement that is currently being evaluated is
  % guaranteed by the correctness of the list of elements to be in that list.
  % The latter fact therefore eliminates the base case, as an empty list does
  % not contain the element we know is in the list.  The other two cases follow
  % by the fact that either the key is equal to the evaluated value of the case
  % expression, or it isn't.  In the first case we can then evaluate the
  % statement and get the state after the case expression, as the uniqueness of
  % the key tells us that the key cannot show up in the list anymore.  In the
  % other case we can just apply the inductive hypothesis and remove the current
  % case from the case statement, as it did not match.
\end{proof}

%\subsection{Coq Mechanisation}

%\JW{Would be nice to include a few high-level metrics here. How many person-years of effort was the proof (very roughly)? How many lines of Coq? How many files, how many lemmas? How long does it take for the Coq proof to execute?}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% TeX-engine: luatex
%%% End:
